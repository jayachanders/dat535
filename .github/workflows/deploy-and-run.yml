name: Data Pipeline on Self-Hosted Runner

on:
  push:
    branches: [ main ]

jobs:
  pipeline:
    runs-on: self-hosted

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Prepare Environment
        run: |
          echo "Verifying virtual environment and dependencies..."
          # Ensure pip is up to date and dependencies are installed in the venv
          /home/ubuntu/spark-env/bin/python -m pip install --upgrade pip
          /home/ubuntu/spark-env/bin/python -m pip install findspark pyspark pandas

      - name: Run Spark Pipeline
        env:
          SPARK_HOME: /opt/spark
          PYSPARK_PYTHON: /home/ubuntu/spark-env/bin/python
          PYTHON_PATH: /home/ubuntu/spark-env/bin/python 
        run: |
          echo "Starting Pipeline execution using $PYTHON_PATH"
          $PYTHON_PATH $GITHUB_WORKSPACE/process_data.py