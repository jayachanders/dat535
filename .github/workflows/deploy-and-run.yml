name: Data Pipeline on Self-Hosted Runner

on:
  push:
    branches: [ main ]

jobs:
  pipeline:
    runs-on: self-hosted

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Run Spark Pipeline
        env:
          SPARK_HOME: /opt/spark
        run: |
          # 1. Activate (Required at the top of every 'run' block that needs it)
          source ~/spark-env/bin/activate

          # 2. Run your code
          echo "Environment activated: $(which python)"
          python $GITHUB_WORKSPACE/process_data.py