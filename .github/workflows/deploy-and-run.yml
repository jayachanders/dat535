name: Data Pipeline on Self-Hosted Runner

on:
  push:
    branches: [ main ]

jobs:
  pipeline:
    runs-on: self-hosted

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Run Spark Pipeline
        env:
          SPARK_HOME: /opt/spark
          JAVA_HOME: /usr/lib/jvm/java-8-openjdk-amd64
        run: |
          # Activate the environment
          source ~/spark-env/bin/activate
          
          # Verify setup
          echo "Python: $(which python)"
          echo "Python version: $(python --version)"
          echo "SPARK_HOME: $SPARK_HOME"
          echo "JAVA_HOME: $JAVA_HOME"
          
          # Run the pipeline
          # python $GITHUB_WORKSPACE/process_data.py

      - name: Run Data Pipeline (Basic)
        env:
          SPARK_HOME: /opt/spark
          JAVA_HOME: /usr/lib/jvm/java-8-openjdk-amd64
        run: |
          # Activate the environment
          source ~/spark-env/bin/activate
          
          # Run the basic data pipeline
          echo "=== Starting Basic Data Pipeline ==="
          python $GITHUB_WORKSPACE/data_pipeline.py
          
          echo "✓ Basic pipeline completed!"
          echo "Data location: ~/pipeline-data/"

      - name: Run MapReduce Pipeline (Advanced)
        env:
          SPARK_HOME: /opt/spark
          JAVA_HOME: /usr/lib/jvm/java-8-openjdk-amd64
        run: |
          # Activate the environment
          source ~/spark-env/bin/activate
          
          # Run the MapReduce pipeline
          echo "=== Starting MapReduce Pipeline ==="
          python $GITHUB_WORKSPACE/mapreduce_pipeline.py
          
          echo "✓ MapReduce pipeline completed!"
          echo "Data location: ~/mapreduce-pipeline-data/"
          
          echo ""
          echo "=== All Pipelines Completed Successfully ==="